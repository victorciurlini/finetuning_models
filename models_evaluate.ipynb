{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes do grupo:\n",
    "- Victor Hugo Ciurlino\n",
    "- Euripedes Antônio da Silva Junior\n",
    "- Ricardo Nascimento de Souza\n",
    "- Danúbia Carvalho Gomes Cantanhede\n",
    "- Pedro Henrique Ferminío Britto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importação das bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciação das funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_dados(dataset_path):\n",
    "    dados = pd.read_excel(dataset_path)\n",
    "\n",
    "    dados = dados.iloc[:,1:]\n",
    "\n",
    "    x = dados.iloc[:,:-1].values\n",
    "    y = dados.iloc[:,-1].values\n",
    "\n",
    "    return x, y, dados\n",
    "\n",
    "def gera_base_treino_teste(dataset_path):\n",
    "\n",
    "    x, y, dados = ler_dados(dataset_path)\n",
    "\n",
    "    dados_embaralhados = dados.sample(frac=1,random_state=54321)\n",
    "\n",
    "    x_treino = dados_embaralhados.iloc[:1297,:-1].values\n",
    "    y_treino = dados_embaralhados.iloc[:1297,-1].values\n",
    "\n",
    "    x_teste = dados_embaralhados.iloc[1297:,:-1].values\n",
    "    y_teste = dados_embaralhados.iloc[1297:,-1].values\n",
    "\n",
    "    return x_treino, x_teste, y_treino, y_teste\n",
    "\n",
    "\n",
    "def avalia_parametros(modelo, param_grid, x_treino, y_treino):\n",
    "    grid_search = GridSearchCV(modelo, param_grid, cv=5, return_train_score=True)\n",
    "    \n",
    "    # Ajustando o modelo com os dados de treinamento\n",
    "    grid_search.fit(x_treino, y_treino)\n",
    "\n",
    "    # Imprimindo os resultados da busca em grade\n",
    "    print(\"Melhores parâmetros: {}\".format(grid_search.best_params_))\n",
    "    print(\"Melhor pontuação de validação cruzada: {:.2f}\".format(grid_search.best_score_))\n",
    "    k = grid_search.best_params_['n_neighbors']\n",
    "    weights = grid_search.best_params_['weights']\n",
    "\n",
    "    return grid_search.best_params_\n",
    "\n",
    "def gera_tabela_metricas(y_teste, y_pred):\n",
    "    accuracy = accuracy_score(y_teste, y_pred)\n",
    "    # matriz_de_confusao = confusion_matrix(y_teste, y_pred)\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_teste, y_pred)\n",
    "    df_report = pd.DataFrame({'precision': precision, 'recall': recall, 'fscore': fscore})\n",
    "\n",
    "    return accuracy, df_report\n",
    "\n",
    "def predict_models(models, lista_parametros, x_treino, y_treino, x_teste, y_teste):\n",
    "    \n",
    "    # List to store the predictions of each model\n",
    "    lista_configuracao = []\n",
    "    # Iterate over the models\n",
    "    for model, hyperparameter in zip(models, lista_parametros):\n",
    "        print(\"Novo modelo:\")\n",
    "        # Create a grid search object to find the best hyperparameters for the current model\n",
    "        clf = GridSearchCV(model, hyperparameter, cv=5, return_train_score=True)\n",
    "\n",
    "        # Fit the grid search object to the training data\n",
    "        clf.fit(x_treino, y_treino)\n",
    "        print(\"Melhores parâmetros: {}\".format(clf.best_params_))\n",
    "        print(\"Melhor pontuação de validação cruzada: {:.2f}\".format(clf.best_score_))\n",
    "        # Make predictions on the test data using the best model found by the grid search\n",
    "        y_pred = clf.predict(x_teste)\n",
    "\n",
    "        # Append the predictions to the list\n",
    "        \n",
    "\n",
    "        accuracy, df_report = gera_tabela_metricas(y_teste, y_pred)\n",
    "        print(f\"Acurácia: {accuracy}\")\n",
    "        # print(df_report)\n",
    "        lista_configuracao.append({'parametros': clf.best_params_,\n",
    "                                    'validacao_cruzada': clf.best_score_,\n",
    "                                    'accuracy': accuracy,\n",
    "                                    'dataframe': df_report})\n",
    "    # Return the list of predictions\n",
    "    return lista_configuracao\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação das variáveis para avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdatasets/Digits.xlsx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m lista_modelos \u001b[39m=\u001b[39m [KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier(), SVC(), LogisticRegression()]\n\u001b[0;32m      3\u001b[0m lista_parametros \u001b[39m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m {\u001b[39m'\u001b[39m\u001b[39mn_neighbors\u001b[39m\u001b[39m'\u001b[39m: [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m31\u001b[39m)],\n\u001b[0;32m      5\u001b[0m  \u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m }\n\u001b[0;32m     24\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_path = 'datasets/Digits.xlsx'\n",
    "lista_modelos = [KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier(), SVC(), LogisticRegression()]\n",
    "lista_parametros = [\n",
    "{'n_neighbors': [i for i in range(1, 31)],\n",
    " 'weights': ['uniform', 'distance']\n",
    " },\n",
    "{'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    " 'min_samples_split': [2, 4, 6, 8, 10 ,12, 14, 16, 18, 20],\n",
    " 'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "{'n_estimators': [10, 50, 100],\n",
    " 'max_depth': [2, 4, 6],\n",
    " 'min_samples_split': [2, 4, 6],\n",
    " 'min_samples_leaf': [1, 2, 3],\n",
    "    },\n",
    "{'C': [0.1, 1.0, 10.0],\n",
    "'kernel': ['linear', 'rbf', 'poly'],\n",
    "'gamma': ['scale', 'auto']\n",
    "},\n",
    "{'penalty': ['l2'],\n",
    " 'C': [0.1, 1.0],\n",
    " 'solver': ['newton-cg']\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição dos melhores parâmetros e avaliação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = gera_base_treino_teste(dataset_path)\n",
    "lista_predicoes = predict_models(lista_modelos, lista_parametros, x_treino, y_treino, x_teste, y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo modelo:\n",
      "Melhores parâmetros: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Melhor pontuação de validação cruzada: 0.99\n",
      "Acurácia: 0.988\n",
      "Novo modelo:\n",
      "Melhores parâmetros: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2}\n",
      "Melhor pontuação de validação cruzada: 0.85\n",
      "Acurácia: 0.846\n",
      "Novo modelo:\n",
      "Melhores parâmetros: {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 6, 'n_estimators': 100}\n",
      "Melhor pontuação de validação cruzada: 0.96\n",
      "Acurácia: 0.926\n",
      "Novo modelo:\n",
      "Melhores parâmetros: {'C': 10.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Melhor pontuação de validação cruzada: 0.99\n",
      "Acurácia: 0.992\n",
      "Novo modelo:\n",
      "Melhores parâmetros: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Melhor pontuação de validação cruzada: 0.96\n",
      "Acurácia: 0.976\n"
     ]
    }
   ],
   "source": [
    "lista_predicoes = predict_models(lista_modelos, lista_parametros, x_treino, y_treino, x_teste, y_teste)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando a acurácia dos modelos, fica claro que os modelos que melhor performam são: LogisticRegression e KNeighborsClassifier, com a melhor combinação de hiperparâmetros dado a lista criada que realiza uma validação cruzada, avaliando todas as combinações possíveis contidas no dicionário de cada modelo. A combinação de hiperparâmetros que resultou no melhor resultado foi:\n",
    "- LogisticRegression\n",
    "    - 'C': 10.0,\n",
    "    - 'gamma': 'scale',\n",
    "    - 'kernel': 'rbf'\n",
    "- KNeighborsClassifier\n",
    "    - 'n_neighbors': 3,\n",
    "    - 'weights': 'uniform'\n",
    "\n",
    "resultando em uma acurácia de 0.99, superando a RandomForestClassifier (0.96) e LogisticRegression(0.96)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b862a2379ac0e784bcc5c26989cf5c652244c2df8377529b03a931f20f3e7e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
